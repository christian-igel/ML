{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "### Christian Igel, 2024\n",
    "\n",
    "\n",
    "I took inspiration from https://github.com/tirthajyoti/Interactive_Machine_Learning by Tirthajyoti Sarkar.\n",
    "I am happy for suggestions to improve the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, IntSlider, Layout, interact_manual, fixed\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rc('text.latex', preamble=r'\\usepackage{amsmath,amsfonts,bm}')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV, Lasso\n",
    "from sklearn.linear_model import RidgeCV, Ridge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression and Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to fit\n",
    "Just some artificial function with Gaussian noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gen(N_samples, noise_sd, resolution=500):\n",
    "    \"\"\"Data generator.\n",
    "    Parameters:\n",
    "        N_samples: data set size\n",
    "        noise_sd: std. deviation of additive zero mean Gaussin noise\n",
    "        resolution: number of equally spaced points for plotting noise-free function\n",
    "    Returns: \n",
    "        x, y: inputs and (noisy) targets\n",
    "        x_lin, y_lin: equally spaced inputs and their noise-free function values \n",
    "        x_min, x_max: input domain\n",
    "    \"\"\"    \n",
    "    def func(x):\n",
    "        return 2*x -0.6*x**2 + 0.2*x**3+12 * np.sin(x)\n",
    "    x_min = -5\n",
    "    x_max = 5\n",
    "    x_lin = np.linspace(x_min, x_max, resolution)  # equally spaced points\n",
    "    x = np.random.choice(x_lin, size=N_samples)  # random points\n",
    "    y = func(x)\n",
    "    y_lin = func(x_lin)\n",
    "    y = y + np.random.normal(scale=noise_sd, size=N_samples)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(x_lin,y_lin,c='C1',lw=2)\n",
    "    plt.scatter(x,y,c='C0',s=60)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    return (x.reshape(-1,1), y, x_lin, y_lin, x_min, x_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the interactive widget with the data generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d56b36518e44b8b82d12e0d9dcb8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, continuous_update=False, description='N_samples', max=200, min=10, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = interactive(func_gen, \n",
    "                N_samples=widgets.IntSlider(min=10,max=200.,step=10,continuous_update=False,value=100),\n",
    "                noise_sd=widgets.FloatSlider(min=0.,max=10.,step=0.5,continuous_update=False,value=2.5),resolution=fixed(500))\n",
    "display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the plot\n",
    "x, y, x_lin, y_lin, x_min, x_max = p.result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear models encapsulated in a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_eps = 0.01\n",
    "lasso_nalpha = 20  # alpha = lambda (= gamma)\n",
    "lasso_iter = 100000  # maximum number of iterative LASSO optimization steps   \n",
    "lasso_tol = 0.0001  # controls a stopping criterion of the LASSO optimization\n",
    "\n",
    "def func_fit(model_type, test_size, degree, alpha, resolution=500):\n",
    "    \"\"\"Fits model to data.\n",
    "    Parameters:\n",
    "        model_type: 'Linear regression', 'Ridge', or 'LASSO'\n",
    "        test_size: percentage of test data\n",
    "        degree: degree of polynomial\n",
    "        alpha: natural logarithm of regularization parameter\n",
    "        resolution: number of equally spaced points for plotting \n",
    "    Returns: \n",
    "        train_score, test_score: training and test score (R2)\n",
    "        model, model_type: model and given model type\n",
    "    \"\"\"    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=55)\n",
    "    \n",
    "    if (model_type=='Linear regression'):\n",
    "        model = make_pipeline(PolynomialFeatures(degree,interaction_only=False), \n",
    "                              LinearRegression(fit_intercept=False))\n",
    "    if (model_type=='Ridge'):    \n",
    "        model = make_pipeline(PolynomialFeatures(degree,interaction_only=False), \n",
    "                              Ridge(alpha=np.exp(alpha), fit_intercept=False, solver='svd'))\n",
    "    if (model_type=='LASSO'):    \n",
    "        model = make_pipeline(PolynomialFeatures(degree,interaction_only=False), \n",
    "                              Lasso(alpha=np.exp(alpha), fit_intercept=False, max_iter=lasso_iter, warm_start=True, positive=False, selection='random'))\n",
    "        \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(X_train)\n",
    "    scaler.transform(X_test)\n",
    "    \n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    train_pred = np.array(model.predict(X_train))\n",
    "    train_score = model.score(X_train,y_train)\n",
    "    \n",
    "    test_pred = np.array(model.predict(X_test))\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    \n",
    "    X_grid = np.linspace(x_min, x_max, resolution).reshape(-1,1)\n",
    "    y_grid = np.array(model.predict(X_grid))\n",
    "    \n",
    "    plt.figure(figsize=(14,6))\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(r\"Test $R^2$ score: %.3f\"%(test_score))\n",
    "    plt.xlabel(r\"$x$\", fontsize=14)\n",
    "    plt.ylabel(r\"$y$\", fontsize=14)\n",
    "    plt.scatter(X_test, y_test, c='C0', s=60, label='Actual test values')\n",
    "    plt.scatter(X_test, test_pred,c='C1', s=40, label='Predicted values')\n",
    "    plt.plot(X_grid, y_grid,label=\"Model\", c='C1', lw=2)\n",
    "    y_min = np.min([y_test.min(), test_pred.min()])\n",
    "    y_max = np.min([y_test.max(), test_pred.max()])\n",
    "    plt.ylim([np.amin([1.1*y_min, 0.9*y_min]), np.amax([1.1*y_max, 0.9*y_max])])\n",
    "    plt.xlim(np.min(X_grid), np.max(X_grid))\n",
    "    plt.plot(x_lin, y_lin, label=\"Function w/o noise\", c='red', lw=2, alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(r\"Training $R^2$ score: %.3f\"%(train_score))\n",
    "    plt.xlabel(r\"$x$\", fontsize=14)\n",
    "    plt.ylabel(r\"$y$\", fontsize=14)\n",
    "    plt.scatter(X_train, y_train, c='C0', label=\"Traning data\", s=60)\n",
    "    plt.scatter(X_train, train_pred, c='C1', label=\"Fitted values\", s=40)\n",
    "    plt.plot(X_grid, y_grid, label=\"Model\", c='C1', lw=2)\n",
    "    y_min = np.min([y_train.min(), train_pred.min()])\n",
    "    y_max = np.min([y_train.max(), train_pred.max()])\n",
    "    plt.ylim([np.amin([1.1*y_min, 0.9*y_min]), np.amax([1.1*y_max, 0.9*y_max])])\n",
    "    plt.xlim(np.min(X_grid), np.max(X_grid))\n",
    "    plt.plot(x_lin, y_lin, label=\"Function w/o noise\", c='red', lw=2, alpha=0.5)\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    #plt.savefig(\"interactiveLinearRegression\"+str(degree)+\".pdf\",bbox_inches='tight')\n",
    "    plt.show()\n",
    "       \n",
    "    return (train_score, test_score, model, model_type)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the encapsulated ML function \n",
    "The score is the coefficient of determination $R^2$, the closer to 1 the better (see assignment).\n",
    "The regularization parameter is referred to as $\\lambda$ (the parameter of the Python function is called `alpha` and in the literature $\\gamma$ is often used). For some setting, the optimization algorithms do not converge (simply ignore the warning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1c9810855a42d0a5bba7b68d224ade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(RadioButtons(description='Choose Model', layout=Layout(width='250px'), options=('Linear …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "style = {'description_width': 'initial'}\n",
    "# Continuous_update = False for IntSlider control to stop continuous model evaluation while the slider is being dragged\n",
    "m = interactive(func_fit,model_type=widgets.RadioButtons(options=['Linear regression','LASSO', 'Ridge'],\n",
    "                                                         description = \"Choose Model\",style=style,\n",
    "                                                         layout=Layout(width='250px')),\n",
    "                test_size=widgets.Dropdown(options={\"10% of data\":0.1,\"25% of data\":0.25, \"50% of data\":0.5, \"75% of data\":0.75},\n",
    "                                           description=\"Test set size\",style=style, value=0.5),\n",
    "                degree=widgets.IntSlider(min=1, max=40, step=1, description= r'Polynomial degree',\n",
    "                                       style=style, continuous_update=False),\n",
    "                alpha=widgets.FloatSlider(min=-15, max=10, step=1, description= r'$\\ln\\lambda$',\n",
    "                                       style=style, continuous_update=False),\n",
    "                resolution=fixed(500))\n",
    "\n",
    "# Display the control\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.16750862  4.70642955]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "e_train, e_text, model, model_type = m.result\n",
    "print(model[1].coef_)\n",
    "\n",
    "plt.xlabel('Parameter number (0 is intercept)')\n",
    "plt.ylabel('Parameter value')\n",
    "plt.grid(axis='y')\n",
    "plt.xticks(np.arange(0, len(model[1].coef_)))\n",
    "plt.bar(np.arange(0, len(model[1].coef_)), model[1].coef_);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation\n",
    "Set parameters and parameter ranges, which should depend on whether the model type is LASSO or Ridge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type=='Linear regression':  # our linear regression has no hyperparameters\n",
    "    model_type = 'Ridge'\n",
    "test_size = .30  # percentage of data used as (external) test set\n",
    "log_lambda_range = np.arange(-5,3)  # range of regularization parameters on logarithmic scale\n",
    "degree_range = np.arange(1,6)  # range of degrees for polynomial representation\n",
    "folds = 5  # number of folds for cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unknown model\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_fold, y_train_fold)\n\u001b[1;32m     36\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mscore(X_val_fold, y_val_fold)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_degree = 0\n",
    "best_log_lambda = 0\n",
    "best_cv_score = 0\n",
    "\n",
    "# (X_train, y_train) are used for cross-validation\n",
    "# (X_test, y_test) are used for testing the model and is not used in training and model selection (cross-validation)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size,random_state=55)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "kf = KFold(n_splits=folds)\n",
    "\n",
    "for degree in degree_range:  # loop over degrees\n",
    "    # Compute polynomial features including constant (bias) feature (include_bias=True)\n",
    "    poly = PolynomialFeatures(degree=degree, interaction_only=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    for log_lambda in log_lambda_range:  # loop of regularization parameters\n",
    "        cv_score = 0\n",
    "        for train_i, val_i in kf.split(X_train_poly):  # loop over cross-validation folds\n",
    "            X_train_fold, y_train_fold = X_train_poly[train_i], y_train[train_i]\n",
    "            X_val_fold, y_val_fold = X_train_poly[val_i], y_train[val_i]\n",
    "    \n",
    "            # Only the current training data is used for scaling\n",
    "            scaler.fit_transform(X_train_fold)\n",
    "            scaler.transform(X_val_fold)\n",
    "     \n",
    "            # Features include constant (bias), so we need not fit an extra intercept \n",
    "            if (model_type=='Ridge'):\n",
    "                model = Ridge(alpha=np.exp(log_lambda), fit_intercept=False)\n",
    "            elif (model_type=='LASSO'):\n",
    "                model = Lasso(alpha=np.exp(log_lambda), fit_intercept=False, max_iter=lasso_iter)\n",
    "            else:\n",
    "                print(\"unknown model: only LASSO and Ridge are supported\")\n",
    "                assert(False)\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "            score = model.score(X_val_fold, y_val_fold)\n",
    "            cv_score += score\n",
    "        if cv_score > best_cv_score:  # found new best score? \n",
    "            best_cv_score = cv_score\n",
    "            best_degree = degree\n",
    "            best_log_lambda = log_lambda\n",
    "\n",
    "print(\"Best average CV score:\", best_cv_score / folds)\n",
    "print(model_type, \" degree:\", best_degree, \"log. lambda:\", best_log_lambda)\n",
    "\n",
    "# After cross-validation, the model \n",
    "#   is trained with the best parameters on the full training data set and \n",
    "#   is evaluated on the external test data\n",
    "poly = PolynomialFeatures(degree=best_degree, interaction_only=False)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly  = poly.transform(X_test)\n",
    "scaler.fit_transform(X_train_poly)\n",
    "scaler.transform(X_test_poly)\n",
    "if (model_type=='Ridge'):\n",
    "    model = Ridge(alpha=np.exp(best_log_lambda), fit_intercept=False, solver='svd')\n",
    "elif (model_type=='LASSO'):\n",
    "    model = Lasso(alpha=np.exp(best_log_lambda), fit_intercept=False, max_iter=lasso_iter)\n",
    "else:\n",
    "    print(\"unknown model\")\n",
    "    assert(False)\n",
    "model.fit(X_train_poly, y_train)\n",
    "score = model.score(X_test_poly, y_test)\n",
    "\n",
    "print(\"Performance best model on test set:\", score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
