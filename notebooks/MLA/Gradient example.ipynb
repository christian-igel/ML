{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "898bb55f",
   "metadata": {},
   "source": [
    "# Simple gradient descent example\n",
    "### Christian Igel, 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135027ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "usetex = True  # set to False if you encounter rendering problems\n",
    "import matplotlib.pyplot as plt\n",
    "if usetex:\n",
    "    plt.rcParams.update({\n",
    "        \"text.usetex\": True,\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": \"Helvetica\",\n",
    "    })\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f1bd0c",
   "metadata": {},
   "source": [
    "Let's define a quadratic function $f:\\mathbb R^2\\to\\mathbb R$  as\n",
    "$$f(x,y)=(\\alpha x)^2 + y^2 + \\alpha xy$$ \n",
    "with $\\alpha = \\frac{1}{2}$ and its gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1ab9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.5  # some parameter changing the shape of the function\n",
    "# Quadratic function\n",
    "def f(x, y):\n",
    "    return (alpha*x)**2 + y**2 + alpha*x*y\n",
    "# Gradient of the function\n",
    "def df(x, y):\n",
    "    return (alpha**2)*2*x + alpha*y, 2*y + alpha*x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d39e23",
   "metadata": {},
   "source": [
    "Now we minimize the function using gradient descent with learning rate `eta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00082249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate\n",
    "eta = 0.5\n",
    "# Number of steps\n",
    "n_iter = 4\n",
    "\n",
    "r = 1.  # we will plot the function over x, y in [-r, r]\n",
    "\n",
    "# Define starting point in the upper right corner of plot\n",
    "xi = 0.9*r  \n",
    "yi = 0.8*r\n",
    "p_x = [xi]  # list of x-values\n",
    "p_y = [yi]  # list of y-values\n",
    "\n",
    "# Do steepest descent optimization:\n",
    "for i in range(n_iter):\n",
    "    dx, dy = df(xi, yi)  # compute gradient\n",
    "    xi -= eta * dx  # update x-coordinate\n",
    "    yi -= eta * dy  # update y-coordinate\n",
    "    p_x.append(xi)  # store x-coordinate\n",
    "    p_y.append(yi)  # store y-coordinate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b36ee43-f5f7-49cd-9e86-c5aca670a90d",
   "metadata": {},
   "source": [
    "Plot steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95363c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make contour plot\n",
    "x = np.linspace(-r, r, 50)\n",
    "y = np.linspace(-r, r, 50)\n",
    "\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "contours = plt.contour(X, Y, Z, [0.01, 0.05, 0.1, 0.5, 1.], colors='grey')\n",
    "plt.clabel(contours, inline=True, fontsize=6)\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$y$')\n",
    "plt.imshow(Z, extent=[-r, r, -r, r], origin='lower', cmap='RdGy', alpha=0.5)\n",
    "\n",
    "# Add optimum\n",
    "plt.plot(0, 0, 'x', c='k')\n",
    "\n",
    "# Plot gradient steps\n",
    "for i in range(n_iter):\n",
    "    plt.arrow(p_x[i], p_y[i], p_x[i+1]-p_x[i], p_y[i+1]-p_y[i], width=.005, head_width=.045, head_length=.025, length_includes_head=True, fc='b', ec='b', zorder=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db1bb8-bea0-4c47-9f43-a73fb3764f91",
   "metadata": {},
   "source": [
    "Modify the example:\n",
    "\n",
    "* Try different values, `eta = 0.01`, `eta = 0.1`, `eta = 0.5`, and `eta = 0.75`, and play with the number of steps.\n",
    "\n",
    "* Add a momentum term to the update step\n",
    "\n",
    "* Reimplement the model in PyTorch and use [automatic differentiation](https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html) to compute the gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
